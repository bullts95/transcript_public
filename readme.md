# çµ±åˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼šHybrid RAG Audio Pipeline

ã“ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯ã€ã‚·ã‚¹ãƒ†ãƒ ãƒ„ãƒ¼ãƒ«ï¼ˆffmpegï¼‰ã¨ã€2ã¤ã®ç•°ãªã‚‹ä»®æƒ³ç’°å¢ƒï¼ˆWhisperç”¨/Pyannoteç”¨ï¼‰ã‚’StreamlitãŒã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆæŒ‡æ®ï¼‰ã™ã‚‹æ§‹é€ ã§ã™ã€‚

### 1. æ©Ÿèƒ½æ¦‚è¦

*   **ğŸ™ï¸ æ–°è¦æ›¸ãèµ·ã“ã—**: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ãƒã‚¤ã‚ºé™¤å»ã€æ–‡å­—èµ·ã“ã—ï¼ˆWhisperï¼‰ã€è©±è€…åˆ†é›¢ï¼ˆPyannoteï¼‰ã‚’ä¸€æ‹¬ã§è¡Œã„ã¾ã™ã€‚
*   **ğŸ“ ä¿®æ­£CSVã‹ã‚‰å‡ºåŠ›ä½œæˆ**: æ‰‹å‹•ã§ä¿®æ­£ã—ãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€HTMLãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚„ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ç”Ÿæˆã—ã¾ã™ã€‚

### 2. ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼å›³

```mermaid
graph TD
    User[ãƒ¦ãƒ¼ã‚¶ãƒ¼] -->|GUI: éŸ³å£°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰| Streamlit
    User -->|GUI: ä¿®æ­£CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰| Streamlit
    Streamlit -->|Step 0: ãƒã‚¤ã‚ºé™¤å»| FFmpeg[System: FFmpeg]
    
    subgraph "WSL2 Environment"
        FFmpeg -->|Clean WAV| FileSystem[(Temp Storage)]
        
        FileSystem -->|Input| WhisperEnv["Env: Whisper (GPU)"]
        FileSystem -->|Input| PyannoteEnv["Env: Pyannote (CPU/GPU)"]
        
        WhisperEnv -->|Step 1: Output JSON| JSON[Transcript JSON]
        PyannoteEnv -->|Step 2: Output RTTM| RTTM[Diarization RTTM]
        
        JSON --> Merger[Step 3: Merge Script]
        RTTM --> Merger
    end
    
    Merger -->|Final CSV| Streamlit
    Streamlit -->|å†ç”Ÿæˆå‡¦ç†| ZIP[Output ZIP]
    ZIP -->|ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰| User
```

### 3. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆï¼ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰

```text
project_root/
â”œâ”€â”€ app.py                  # ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒª (Streamlit)
â”œâ”€â”€ requirements.txt        # app.pyç”¨ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª (streamlit, pandas)
â”œâ”€â”€ temp/                   # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å ´æ‰€ (è‡ªå‹•ç”Ÿæˆ)
â””â”€â”€ scripts/                # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆç¾¤
    â”œâ”€â”€ step1_transcribe.py    # Whisperç’°å¢ƒã§å‹•ã‹ã™
    â”œâ”€â”€ step2_diarize.py       # Pyannoteç’°å¢ƒã§å‹•ã‹ã™
    â””â”€â”€ step3_merge.py         # çµ±åˆãƒ­ã‚¸ãƒƒã‚¯ (ã©ã®ç’°å¢ƒã§ã‚‚å¯)
```

### 4. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯3ã¤ã®ä»®æƒ³ç’°å¢ƒã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ãã‚Œãã‚Œã®ç’°å¢ƒç”¨ã®requirements.txtãƒ•ã‚¡ã‚¤ãƒ«ãŒ`requirements/`ãƒ•ã‚©ãƒ«ãƒ€ã«ç”¨æ„ã•ã‚Œã¦ã„ã¾ã™ã€‚

#### 4.1. System Levelã®æº–å‚™

WSL2 Ubuntu ã« `ffmpeg` ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼š

```bash
sudo apt update && sudo apt install ffmpeg
```

#### 4.2. ä»®æƒ³ç’°å¢ƒã®ä½œæˆã¨ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# 1. Whisperç’°å¢ƒï¼ˆROCmå¯¾å¿œPyTorch + openai-whisperï¼‰
python3 -m venv envs/whisper_env
source envs/whisper_env/bin/activate
pip install -r requirements/requirements_whisper.txt
deactivate

# 2. Pyannoteç’°å¢ƒï¼ˆpyannote-audioï¼‰
python3 -m venv envs/pyannote_env
source envs/pyannote_env/bin/activate
pip install -r requirements/requirements_pyannote.txt
deactivate

# 3. Streamlitã‚¢ãƒ—ãƒªç’°å¢ƒ
python3 -m venv envs/app_env
source envs/app_env/bin/activate
pip install -r requirements/requirements_app.txt
deactivate
```

#### 4.3. Pythonãƒ‘ã‚¹ã®è¨­å®š

`app.py`å†…ã§å„ä»®æƒ³ç’°å¢ƒã®Pythonãƒ‘ã‚¹ã‚’è¨­å®šã—ã¦ãã ã•ã„ï¼š

```python
WHISPER_PYTHON_PATH = "/path/to/your/project/envs/whisper_env/bin/python"
PYANNOTE_PYTHON_PATH = "/path/to/your/project/envs/pyannote_env/bin/python"
```

### 5. é–‹ç™ºè€…ã¸ã®é‡è¦ä¼é”äº‹é …

1.  **System Level**:
      * WSL2 Ubuntu ã« `ffmpeg` ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã€‚
2.  **Virtual Envs**:
      * `whisper_env`: ROCmå¯¾å¿œPyTorch + openai-whisper ãŒå…¥ã£ã¦ã„ã‚‹ã“ã¨ã€‚
      * `pyannote_env`: PyannoteãŒè¦æ±‚ã™ã‚‹PyTorch + pyannote-audio ãŒå…¥ã£ã¦ã„ã‚‹ã“ã¨ã€‚
      * `app_env`: streamlit + pandas ãŒå…¥ã£ã¦ã„ã‚‹ã“ã¨ã€‚
3.  **Scripts**:
      * `scripts/` ãƒ•ã‚©ãƒ«ãƒ€å†…ã®3ã¤ã®Pythonãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ï¼ˆargparseï¼‰ã§ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å—ã‘å–ã‚‹ã‚ˆã†ã«å®Ÿè£…ã™ã‚‹ã“ã¨ã€‚

ã“ã®æ§‹æˆã§ã‚ã‚Œã°ã€è¤‡é›‘ãªä¾å­˜é–¢ä¿‚ã«æ‚©ã¾ã•ã‚Œã‚‹ã“ã¨ãªãã€GUIãƒ™ãƒ¼ã‚¹ã§å¿«é©ã«é«˜ç²¾åº¦ãªéŸ³å£°èªè­˜ãƒ»è©±è€…åˆ†é›¢ã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚

### 6. License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

### 7. Acknowledgements

This project makes use of the following open-source projects:

*   **[OpenAI Whisper](https://github.com/openai/whisper)**: Robust Speech Recognition via Large-Scale Weak Supervision. (MIT License)
*   **[pyannote-audio](https://github.com/pyannote/pyannote-audio)**: Neural building blocks for speaker diarization. (MIT License)
*   **[Streamlit](https://streamlit.io/)**: The fastest way to build and share data apps. (Apache 2.0 License)
